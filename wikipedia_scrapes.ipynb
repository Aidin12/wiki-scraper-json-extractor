{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aidin12/wiki-scraper-json-extractor/blob/main/wikipedia_scrapes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_41flvMg7ly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2bf31b-f5f6-4d21-d763-ee852991b286"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2MK7k4xhQSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faecf723-e999-4974-ec78-44c26dd9f2f9"
      },
      "source": [
        "!pip install selenium\n",
        "!pip install Scrapy\n",
        "!apt update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\r\u001b[K     |▍                               | 10kB 12.9MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 9.5MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 7.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 71kB 4.7MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 102kB 5.7MB/s eta 0:00:01\r\u001b[K     |████                            | 112kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 122kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 133kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 143kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 153kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 163kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 174kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 184kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 194kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 204kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 215kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 225kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 235kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 245kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 256kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 266kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 276kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 286kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 296kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 307kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 317kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 327kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 337kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 348kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 358kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 368kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 378kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 389kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 399kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 409kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 419kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 430kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 440kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 450kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 460kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 471kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 481kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 491kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 501kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 512kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 522kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 532kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 542kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 552kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 563kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 573kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 583kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 593kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 604kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 614kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 624kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 634kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 645kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 655kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 665kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 675kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 686kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 696kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 706kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 716kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 727kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 737kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 747kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 757kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 768kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 778kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 788kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 798kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 808kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 819kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 829kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 839kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 849kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 860kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 870kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 880kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 890kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 901kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 911kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Collecting Scrapy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/16/3c7c37caf25f91aa21db194655515718c2a15f704f9f5c59a194f5c83db0/Scrapy-2.4.1-py2.py3-none-any.whl (239kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 4.1MB/s \n",
            "\u001b[?25hCollecting service-identity>=16.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/7c/2195b890023e098f9618d43ebc337d83c8b38d414326685339eb024db2f6/service_identity-18.1.0-py2.py3-none-any.whl\n",
            "Collecting w3lib>=1.17.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/59/b6b14521090e7f42669cafdb84b0ab89301a42f1f1a82fcf5856661ea3a7/w3lib-1.22.0-py2.py3-none-any.whl\n",
            "Collecting parsel>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/23/1e/9b39d64cbab79d4362cdd7be7f5e9623d45c4a53b3f7522cd8210df52d8e/parsel-1.6.0-py2.py3-none-any.whl\n",
            "Collecting PyDispatcher>=2.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/37/39aca520918ce1935bea9c356bcbb7ed7e52ad4e31bff9b943dfc8e7115b/PyDispatcher-2.0.5.tar.gz\n",
            "Collecting zope.interface>=4.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/57/8a68360d697cf9159cba5ee35f2d25bdcda33883e8b5a997714a191a0b11/zope.interface-5.3.0-cp37-cp37m-manylinux2010_x86_64.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 7.5MB/s \n",
            "\u001b[?25hCollecting itemadapter>=0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/88/83/ab33780fd93278e699561d61862d27343c95d3fe0a0081acd73e8e26a649/itemadapter-0.2.0-py3-none-any.whl\n",
            "Collecting pyOpenSSL>=16.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/5e/06351ede29fd4899782ad335c2e02f1f862a887c20a3541f17c3fa1a3525/pyOpenSSL-20.0.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.5.0; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.7/dist-packages (from Scrapy) (4.2.6)\n",
            "Collecting cryptography>=2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/1f/acde6ff69864c5e78b56488e3afd93c1ccc8c2651186e2a5f93d93f64859/cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 8.0MB/s \n",
            "\u001b[?25hCollecting protego>=0.1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6e/bf6d5e4d7cf233b785719aaec2c38f027b9c2ed980a0015ec1a1cced4893/Protego-0.1.16.tar.gz (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 39.1MB/s \n",
            "\u001b[?25hCollecting itemloaders>=1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/2b/eb2ddf7becf834679273a6f79ffdc6fbedf07c5272e2eddf412582143c0e/itemloaders-1.0.4-py3-none-any.whl\n",
            "Collecting cssselect>=0.9.1\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Collecting Twisted>=17.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/16/3eb9c66a7bfb5220c7bcbaaac33d359fe8a157b028959cd210983749b2e0/Twisted-21.2.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 43.1MB/s \n",
            "\u001b[?25hCollecting queuelib>=1.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/85/ae64e9145f39dd6d14f8af3fa809a270ef3729f3b90b3c0cf5aa242ab0d4/queuelib-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=16.0.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->Scrapy) (20.3.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->Scrapy) (0.2.8)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->Scrapy) (0.4.8)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from w3lib>=1.17.0->Scrapy) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface>=4.1.3->Scrapy) (54.1.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->Scrapy) (1.14.5)\n",
            "Collecting jmespath>=0.9.5\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting hyperlink>=17.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/aa/8caf6a0a3e62863cbb9dab27135660acba46903b703e224f14f447e57934/hyperlink-21.0.0-py2.py3-none-any.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.9MB/s \n",
            "\u001b[?25hCollecting incremental>=16.10.1\n",
            "  Downloading https://files.pythonhosted.org/packages/99/3b/4f80dd10cb716f3a9e22ae88f026d25c47cc3fdf82c2747f3d59c98e4ff1/incremental-21.3.0-py2.py3-none-any.whl\n",
            "Collecting constantly>=15.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/65/48c1909d0c0aeae6c10213340ce682db01b48ea900a7d9fce7a7910ff318/constantly-15.1.0-py2.py3-none-any.whl\n",
            "Collecting Automat>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/dd/83/5f6f3c1a562674d65efc320257bdc0873ec53147835aeef7762fe7585273/Automat-20.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->Scrapy) (2.20)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->Scrapy) (2.10)\n",
            "Building wheels for collected packages: PyDispatcher, protego\n",
            "  Building wheel for PyDispatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.5-cp37-none-any.whl size=11517 sha256=c9f5f09e17b72bff072a4ba535a72901a9927b205edb5a71f48461f8041a8fd2\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/99/96/cfef6665f9cb1522ee6757ae5955feedf2fe25f1737f91fa7f\n",
            "  Building wheel for protego (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for protego: filename=Protego-0.1.16-cp37-none-any.whl size=7766 sha256=8199d044fd3827d53f2e8e26bfe475ed7dbde7fbd7052b687b5f37f11c0d215c\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/01/d1/4a2286a976dccd025ba679acacfe37320540df0f2283ecab12\n",
            "Successfully built PyDispatcher protego\n",
            "Installing collected packages: cryptography, service-identity, w3lib, cssselect, parsel, PyDispatcher, zope.interface, itemadapter, pyOpenSSL, protego, jmespath, itemloaders, hyperlink, incremental, constantly, Automat, Twisted, queuelib, Scrapy\n",
            "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 Scrapy-2.4.1 Twisted-21.2.0 constantly-15.1.0 cryptography-3.4.6 cssselect-1.1.0 hyperlink-21.0.0 incremental-21.3.0 itemadapter-0.2.0 itemloaders-1.0.4 jmespath-0.10.0 parsel-1.6.0 protego-0.1.16 pyOpenSSL-20.0.1 queuelib-1.5.0 service-identity-18.1.0 w3lib-1.22.0 zope.interface-5.3.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,400 kB]\n",
            "Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [344 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,031 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,748 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,460 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [894 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [373 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,168 kB]\n",
            "Get:24 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [49.4 kB]\n",
            "Fetched 11.8 MB in 4s (3,019 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "57 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 57 not upgraded.\n",
            "Need to get 83.2 MB of archives.\n",
            "After this operation, 282 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 89.0.4389.82-0ubuntu0.18.04.1 [1,127 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 89.0.4389.82-0ubuntu0.18.04.1 [73.6 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 89.0.4389.82-0ubuntu0.18.04.1 [3,800 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 89.0.4389.82-0ubuntu0.18.04.1 [4,697 kB]\n",
            "Fetched 83.2 MB in 4s (19.9 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 160980 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_89.0.4389.82-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_89.0.4389.82-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_89.0.4389.82-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_89.0.4389.82-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2orDp0hhZDB"
      },
      "source": [
        "# %cd gdrive/My Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDPaMP03hZLY",
        "outputId": "2d7b2878-6afc-44a0-cb2a-8e9976264427"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Wikipedia/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Wikipedia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCtUWoCsmxmt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "b045b4c9-fccd-4e29-ba79-fd8e5861b808"
      },
      "source": [
        "from scrapy import Spider\n",
        "from selenium import webdriver\n",
        "from scrapy.selector import Selector #to gather urls from entire site\n",
        "from scrapy.http import Request\n",
        "from time import sleep\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9db90207ed13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelector\u001b[0m \u001b[0;31m#to gather urls from entire site\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scrapy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX3CTyAfi3NN"
      },
      "source": [
        "# !scrapy startproject wiki_crawler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-U5pHAni3Vq"
      },
      "source": [
        "# !cd wiki_crawler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD4GhtILjA-e"
      },
      "source": [
        "# !scrapy genspider wikispider pageviews.toolforge.org"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNsDpL6hhQfw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "a29eb77f-bd41-4357-a172-2b76c88c971e"
      },
      "source": [
        "import scrapy\n",
        "from scrapy.crawler import CrawlerProcess\n",
        "from scrapy.linkextractors import LinkExtractor\n",
        "import pandas as pd\n",
        "\n",
        "!gdown --id 1M98aMkqwssJtjXUZFKgJlbNU6FN2hoH0\n",
        "\n",
        "sp500 = pd.read_csv('SP500.csv')\n",
        "sp500_tickers = list(sp500.Ticker)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f96b6b7645cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrawler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrawlerProcess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinkextractors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinkExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scrapy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyBsK5c5zaSV"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class wikiTrends():\n",
        "\n",
        "  def __init__(self, start, end, search):\n",
        "    self.search = search\n",
        "    self.st = datetime.strptime('01/01/16', '%m/%d/%y')\n",
        "    self.en = datetime.strptime('01/03/21', '%m/%d/%y')\n",
        "    self.smonth = self._padZero(self.st.month)\n",
        "    self.emonth = self._padZero(self.en.month)\n",
        "    self.sday = self._padZero(self.st.day)\n",
        "    self.eday = self._padZero(self.en.day)\n",
        "\n",
        "  def getURL(self):\n",
        "    s = f'{self.st.year}-{self.smonth}-{self.sday}'\n",
        "    e = f'{self.en.year}-{self.emonth}-{self.eday}'\n",
        "    #terms = f'pages={self.search}_(NASDAQ)|{self.search}(NASDAQ)|{self.search}'\n",
        "    terms = f'pages={self.search}'\n",
        "\n",
        "    url_start = 'https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start='\n",
        "    full_url = f'{url_start}{s}&end={e}&{terms}'\n",
        "    return full_url\n",
        "\n",
        "  def _padZero(self, date):\n",
        "      if len(str(date)) == 1:\n",
        "          return '0'+str(date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSrhPsLQLUl4"
      },
      "source": [
        "class WikiSpider(Spider):\n",
        "\n",
        "    #print(url)\n",
        "    name = 'wiki'\n",
        "    allowed_domains = ['pageviews.toolforge.org']\n",
        "    #start_urls = url\n",
        "\n",
        "    def __init__(self, url=None, *args, **kwargs):\n",
        "        super(WikiSpider, self).__init__(*args, **kwargs)\n",
        "        self.start_urls = url\n",
        "\n",
        "    def start_requests(self):\n",
        "\n",
        "        self.driver = webdriver.Chrome(options=options)\n",
        "        self.driver.get(self.start_urls)\n",
        "\n",
        "        try:\n",
        "            download1 = self.driver.find_element_by_xpath('//html/body/main/div[2]/div/div')\n",
        "            download2 = self.driver.find_element_by_xpath('//html/body/main/div[2]/div/div/ul/li[1]/a')\n",
        "            sleep(1)\n",
        "            self.logger.info('downloading')\n",
        "            download1.click()\n",
        "            sleep(1)\n",
        "            download2.click()\n",
        "            sleep(1)\n",
        "\n",
        "        except NoSuchElementException:\n",
        "            self.driver.quit()\n",
        "            print(\"Faulty URL\")\n",
        "\n",
        "    def parse_wiki(self, response):\n",
        "        pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z30nzxAjBSzi",
        "outputId": "0bf22c3c-9fd6-4715-bf39-9f84ec3ec16f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/Wikipedia/\n",
        "\n",
        "import glob\n",
        "from scrapy import Spider\n",
        "from selenium import webdriver\n",
        "from scrapy.selector import Selector #to gather urls from entire site\n",
        "from scrapy.http import Request\n",
        "from time import sleep\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "import scrapy\n",
        "from scrapy.crawler import CrawlerProcess\n",
        "from scrapy.linkextractors import LinkExtractor\n",
        "import pandas as pd\n",
        "\n",
        "!gdown --id 1M98aMkqwssJtjXUZFKgJlbNU6FN2hoH0\n",
        "\n",
        "sp500 = pd.read_csv('SP500.csv')\n",
        "sp500_tickers = list(sp500.Ticker)\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "class wikiTrends():\n",
        "\n",
        "  def __init__(self, start, end, search):\n",
        "    self.search = search\n",
        "    self.st = datetime.strptime('01/01/16', '%m/%d/%y')\n",
        "    self.en = datetime.strptime('01/03/21', '%m/%d/%y')\n",
        "    self.smonth = self._padZero(self.st.month)\n",
        "    self.emonth = self._padZero(self.en.month)\n",
        "    self.sday = self._padZero(self.st.day)\n",
        "    self.eday = self._padZero(self.en.day)\n",
        "\n",
        "  def getURL(self):\n",
        "    s = f'{self.st.year}-{self.smonth}-{self.sday}'\n",
        "    e = f'{self.en.year}-{self.emonth}-{self.eday}'\n",
        "    terms = f'pages={self.search}_(NASDAQ)|{self.search}(NASDAQ)|{self.search}'\n",
        "    #terms = f'pages={self.search}'\n",
        "\n",
        "    url_start = 'https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start='\n",
        "    full_url = f'{url_start}{s}&end={e}&{terms}'\n",
        "    return full_url\n",
        "\n",
        "  def _padZero(self, date):\n",
        "      if len(str(date)) == 1:\n",
        "          return '0'+str(date)\n",
        "\n",
        "class WikiSpider(Spider):\n",
        "\n",
        "    #print(url)\n",
        "    name = 'wiki'\n",
        "    allowed_domains = ['pageviews.toolforge.org']\n",
        "    #start_urls = url\n",
        "\n",
        "    def __init__(self, url=None, *args, **kwargs):\n",
        "        super(WikiSpider, self).__init__(*args, **kwargs)\n",
        "        self.start_urls = url\n",
        "\n",
        "    def start_requests(self):\n",
        "\n",
        "        self.driver = webdriver.Chrome(options=options)\n",
        "        self.driver.get(self.start_urls)\n",
        "\n",
        "        try:\n",
        "            download1 = self.driver.find_element_by_xpath('//html/body/main/div[2]/div/div')\n",
        "            download2 = self.driver.find_element_by_xpath('//html/body/main/div[2]/div/div/ul/li[1]/a')\n",
        "            sleep(1)\n",
        "            self.logger.info('downloading')\n",
        "            download1.click()\n",
        "            sleep(1)\n",
        "            download2.click()\n",
        "            sleep(1)\n",
        "\n",
        "        except NoSuchElementException:\n",
        "            self.driver.quit()\n",
        "            print(\"Faulty URL\")\n",
        "\n",
        "    def parse_wiki(self, response):\n",
        "        pass\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Wikipedia\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1M98aMkqwssJtjXUZFKgJlbNU6FN2hoH0\n",
            "To: /content/gdrive/My Drive/Wikipedia/SP500.csv\n",
            "100% 85.3k/85.3k [00:00<00:00, 24.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4IYCYXkre5z",
        "outputId": "e0c473bb-df00-4ff6-8ea2-8ddb07ee8d33"
      },
      "source": [
        "import glob\n",
        "\n",
        "scraped = glob.glob(\"*.csv\")\n",
        "scraped"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SP500.csv',\n",
              " 'AAPL_2016_2021.csv',\n",
              " 'MSFT_2016_2021.csv',\n",
              " 'AMZN_2016_2021.csv',\n",
              " 'FB_2016_2021.csv',\n",
              " 'TSLA_2016_2021.csv',\n",
              " 'SNE_2016_2021.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9sLYUcyv0uG",
        "outputId": "1ad41a8c-088a-4d84-9f8a-e4c96a54da7b"
      },
      "source": [
        "file_name = 'AAPL_2016_2021.csv'\n",
        "if file_name in scraped:\n",
        "  print(True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g419fk9WENTx",
        "outputId": "0a6e3e70-bb7a-4f72-cac4-594b43af2013"
      },
      "source": [
        "sp500_tickers = ['AAPL','MSFT','AMZN','FB','TSLA']\n",
        "print(len(sp500_tickers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J5CCKIRwZwy",
        "outputId": "6a018e4d-f346-49f3-af59-ea26a1762577"
      },
      "source": [
        "import os\n",
        "from itertools import cycle\n",
        "\n",
        "sp500_tickers = ['AAPL','MSFT','AMZN','FB']\n",
        "scraped = glob.glob(\"*.csv\")\n",
        "#print(len(sp500_tickers))\n",
        "\n",
        "pool = cycle(sp500_tickers)\n",
        "count = 0\n",
        "\n",
        "for ticker in pool:\n",
        "    file_name = f'{ticker}_2016_2021.csv'\n",
        "\n",
        "    if file_name in scraped:\n",
        "      count += 1\n",
        "      print(file_name, count)\n",
        "      if count == len(sp500_tickers):\n",
        "        print('Done', count)\n",
        "        break\n",
        "\n",
        "    else:\n",
        "      count = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AAPL_2016_2021.csv 1\n",
            "MSFT_2016_2021.csv 2\n",
            "AMZN_2016_2021.csv 3\n",
            "FB_2016_2021.csv 4\n",
            "Done 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zydAdX32EBxg",
        "outputId": "fb535045-42eb-4cc0-afe8-a0858c9c38bc"
      },
      "source": [
        "print(len(sp500_tickers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxqPRFX5seeW"
      },
      "source": [
        "import os\n",
        "from itertools import cycle\n",
        "\n",
        "# Set parameters MM/DD/YY\n",
        "start = '01/01/16'\n",
        "end = '01/03/21'\n",
        "\n",
        "#sp500_tickers = ['AAPL','MSFT','AMZN','FB','TSLA','SNE']\n",
        "scraped = glob.glob(\"*.csv\")\n",
        "print(len(sp500_tickers))\n",
        "\n",
        "unable_to_scrape = []\n",
        "\n",
        "pool = cycle(sp500_tickers)\n",
        "count = 0\n",
        "\n",
        "for ticker in pool:\n",
        "    scraped = glob.glob(\"*.csv\")\n",
        "    print(f'[INFO] Scraped {len(scraped)} tickers - {scraped}')\n",
        "    file_name = f'{ticker}_2016_2021.csv'\n",
        "    print(f'[INFO] Looking for {file_name}')\n",
        "\n",
        "    if file_name in scraped:\n",
        "      count += 1\n",
        "      print(f'[INFO] {file_name} scraped already count = {count}')\n",
        "      if count == len(sp500_tickers):\n",
        "        print('Done', count)\n",
        "        break\n",
        "\n",
        "    else:\n",
        "      count = 0\n",
        "      wk = wikiTrends(start, end, ticker)\n",
        "      link = wk.getURL()\n",
        "      print(f'[INFO] Scraping {ticker} - {link}')\n",
        "      process = CrawlerProcess()\n",
        "      process.crawl(WikiSpider, url=link)\n",
        "      process.start()\n",
        "      sleep(15)\n",
        "\n",
        "      try:\n",
        "        os.rename('pageviews-20160101-20210103.csv', file_name)\n",
        "      except:\n",
        "        unable_to_scrape.append(ticker)\n",
        "        print('[INFO] Failed to rename file')\n",
        "        pass\n",
        "\n",
        "print(unable_to_scrape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "tuf_A6P6JULQ",
        "outputId": "3ca71e97-573d-4c37-9cd8-8a10e9a588be"
      },
      "source": [
        "print(unable_to_scrape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5b40b9bc6a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munable_to_scrape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'unable_to_scrape' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nXVF1q4ALRRb",
        "outputId": "6c6371b3-19d1-4c95-f244-1e87b73fd26f"
      },
      "source": [
        "import os\n",
        "from itertools import cycle\n",
        "\n",
        "# Set parameters MM/DD/YY\n",
        "start = '01/01/16'\n",
        "end = '01/03/21'\n",
        "\n",
        "pool = cycle(sp500_tickers)\n",
        "count = 0\n",
        "\n",
        "for ticker in pool:\n",
        "    file_name = f'{ticker}_2016_2021.csv'\n",
        "\n",
        "    if file_name not in scraped:\n",
        "      count = 0\n",
        "      wk = wikiTrends(start, end, ticker)\n",
        "      link = wk.getURL()\n",
        "      print(f'Scraping {ticker} - {link}')\n",
        "      process = CrawlerProcess()\n",
        "      process.crawl(WikiSpider, url=link)\n",
        "      process.start()\n",
        "      sleep(15)\n",
        "\n",
        "      try:\n",
        "        os.rename('pageviews-20160101-20210103.csv', file_name)\n",
        "      except:\n",
        "        pass\n",
        "    else:\n",
        "      count += 1\n",
        "      if count == len(sp500_tickers)-1:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:27:22 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 00:27:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 00:27:22 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-24 00:27:22 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 00:27:22 [scrapy.extensions.telnet] INFO: Telnet Password: 8e1f477049c36cdb\n",
            "2021-03-24 00:27:22 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-24 00:27:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 00:27:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 00:27:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping AAPL - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=AAPL\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:27:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57251/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 00:27:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:57251\n",
            "2021-03-24 00:27:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57251 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 00:27:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:27:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57251/session/30f7405b7477d7e05aadb50cc54f25e0/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=AAPL\"}\n",
            "2021-03-24 00:27:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57251 \"POST /session/30f7405b7477d7e05aadb50cc54f25e0/url HTTP/1.1\" 200 14\n",
            "2021-03-24 00:27:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:27:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57251/session/30f7405b7477d7e05aadb50cc54f25e0/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 00:27:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57251 \"POST /session/30f7405b7477d7e05aadb50cc54f25e0/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:27:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:27:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57251/session/30f7405b7477d7e05aadb50cc54f25e0/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 00:27:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57251 \"POST /session/30f7405b7477d7e05aadb50cc54f25e0/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:27:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:27:25 [wiki] INFO: downloading\n",
            "2021-03-24 00:27:25 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57251/session/30f7405b7477d7e05aadb50cc54f25e0/element/e2640bab-0d66-42bb-ade8-fc3ea324b189/click {\"id\": \"e2640bab-0d66-42bb-ade8-fc3ea324b189\"}\n",
            "2021-03-24 00:27:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57251 \"POST /session/30f7405b7477d7e05aadb50cc54f25e0/element/e2640bab-0d66-42bb-ade8-fc3ea324b189/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:27:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:27:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57251/session/30f7405b7477d7e05aadb50cc54f25e0/element/a41917a0-c1f4-42e2-9a41-09c9b17b0a73/click {\"id\": \"a41917a0-c1f4-42e2-9a41-09c9b17b0a73\"}\n",
            "2021-03-24 00:27:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57251 \"POST /session/30f7405b7477d7e05aadb50cc54f25e0/element/a41917a0-c1f4-42e2-9a41-09c9b17b0a73/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:27:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:27:43 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 00:27:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 00:27:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-24 00:27:43 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 00:27:43 [scrapy.extensions.telnet] INFO: Telnet Password: 9b81575e34026561\n",
            "2021-03-24 00:27:43 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-24 00:27:43 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 00:27:43 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 00:27:43 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping MSFT - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=MSFT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:27:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53777/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 00:27:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:53777\n",
            "2021-03-24 00:27:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53777 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 00:27:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:27:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53777/session/d494543b16728a670abd1c8f592335b9/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=MSFT\"}\n",
            "2021-03-24 00:27:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53777 \"POST /session/d494543b16728a670abd1c8f592335b9/url HTTP/1.1\" 200 14\n",
            "2021-03-24 00:27:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:27:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53777/session/d494543b16728a670abd1c8f592335b9/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 00:27:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53777 \"POST /session/d494543b16728a670abd1c8f592335b9/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:27:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:27:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53777/session/d494543b16728a670abd1c8f592335b9/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 00:27:45 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53777 \"POST /session/d494543b16728a670abd1c8f592335b9/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:27:45 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:27:46 [wiki] INFO: downloading\n",
            "2021-03-24 00:27:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53777/session/d494543b16728a670abd1c8f592335b9/element/b12f1ac4-360b-4265-bfbd-999cd91e9a88/click {\"id\": \"b12f1ac4-360b-4265-bfbd-999cd91e9a88\"}\n",
            "2021-03-24 00:27:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53777 \"POST /session/d494543b16728a670abd1c8f592335b9/element/b12f1ac4-360b-4265-bfbd-999cd91e9a88/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:27:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:27:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53777/session/d494543b16728a670abd1c8f592335b9/element/03c92b48-98dc-4a8c-868c-e2d9c667fd3a/click {\"id\": \"03c92b48-98dc-4a8c-868c-e2d9c667fd3a\"}\n",
            "2021-03-24 00:27:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53777 \"POST /session/d494543b16728a670abd1c8f592335b9/element/03c92b48-98dc-4a8c-868c-e2d9c667fd3a/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:27:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "Unhandled error in Deferred:\n",
            "2021-03-24 00:28:04 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:28:04 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 192, in crawl\n",
            "    return self._crawl(crawler, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 196, in _crawl\n",
            "    d = crawler.crawl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1656, in unwindGenerator\n",
            "    return _cancellableInlineCallbacks(gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1571, in _cancellableInlineCallbacks\n",
            "    _inlineCallbacks(None, g, status)\n",
            "--- <exception caught here> ---\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "builtins.TypeError: 'NoneType' object is not iterable\n",
            "\n",
            "2021-03-24 00:28:04 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:28:04 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:28:04 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 00:28:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 00:28:04 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-24 00:28:04 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 00:28:04 [scrapy.extensions.telnet] INFO: Telnet Password: 390ddea3bd5bb219\n",
            "2021-03-24 00:28:04 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-24 00:28:04 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 00:28:04 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 00:28:04 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping AMZN - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=AMZN\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:28:05 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53123/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 00:28:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:53123\n",
            "2021-03-24 00:28:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53123 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 00:28:05 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:05 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53123/session/8e29ac4c931aad2c3a01ade0799f9bae/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=AMZN\"}\n",
            "2021-03-24 00:28:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53123 \"POST /session/8e29ac4c931aad2c3a01ade0799f9bae/url HTTP/1.1\" 200 14\n",
            "2021-03-24 00:28:06 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:06 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53123/session/8e29ac4c931aad2c3a01ade0799f9bae/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 00:28:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53123 \"POST /session/8e29ac4c931aad2c3a01ade0799f9bae/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:28:06 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:06 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53123/session/8e29ac4c931aad2c3a01ade0799f9bae/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 00:28:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53123 \"POST /session/8e29ac4c931aad2c3a01ade0799f9bae/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:28:06 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:07 [wiki] INFO: downloading\n",
            "2021-03-24 00:28:07 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53123/session/8e29ac4c931aad2c3a01ade0799f9bae/element/dd612f49-2d21-4e11-b694-c81294489227/click {\"id\": \"dd612f49-2d21-4e11-b694-c81294489227\"}\n",
            "2021-03-24 00:28:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53123 \"POST /session/8e29ac4c931aad2c3a01ade0799f9bae/element/dd612f49-2d21-4e11-b694-c81294489227/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:28:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53123/session/8e29ac4c931aad2c3a01ade0799f9bae/element/19efa141-642e-478e-a636-d81048ca3724/click {\"id\": \"19efa141-642e-478e-a636-d81048ca3724\"}\n",
            "2021-03-24 00:28:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53123 \"POST /session/8e29ac4c931aad2c3a01ade0799f9bae/element/19efa141-642e-478e-a636-d81048ca3724/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:28:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "Unhandled error in Deferred:\n",
            "2021-03-24 00:28:25 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:28:25 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:28:25 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 192, in crawl\n",
            "    return self._crawl(crawler, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 196, in _crawl\n",
            "    d = crawler.crawl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1656, in unwindGenerator\n",
            "    return _cancellableInlineCallbacks(gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1571, in _cancellableInlineCallbacks\n",
            "    _inlineCallbacks(None, g, status)\n",
            "--- <exception caught here> ---\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "builtins.TypeError: 'NoneType' object is not iterable\n",
            "\n",
            "2021-03-24 00:28:25 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:28:25 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:28:25 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:28:25 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 00:28:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 00:28:25 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-24 00:28:25 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 00:28:25 [scrapy.extensions.telnet] INFO: Telnet Password: 9a24626ba72b26c0\n",
            "2021-03-24 00:28:25 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-24 00:28:25 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 00:28:25 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 00:28:25 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping FB - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=FB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:28:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:45927/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 00:28:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:45927\n",
            "2021-03-24 00:28:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:45927 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 00:28:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:45927/session/3b66764fbba8f980b1c3d62e516524c6/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=FB\"}\n",
            "2021-03-24 00:28:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:45927 \"POST /session/3b66764fbba8f980b1c3d62e516524c6/url HTTP/1.1\" 200 14\n",
            "2021-03-24 00:28:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:45927/session/3b66764fbba8f980b1c3d62e516524c6/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 00:28:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:45927 \"POST /session/3b66764fbba8f980b1c3d62e516524c6/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:28:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:45927/session/3b66764fbba8f980b1c3d62e516524c6/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 00:28:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:45927 \"POST /session/3b66764fbba8f980b1c3d62e516524c6/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:28:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:28 [wiki] INFO: downloading\n",
            "2021-03-24 00:28:28 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:45927/session/3b66764fbba8f980b1c3d62e516524c6/element/ed399fd0-eda6-4227-99a8-9155251bec15/click {\"id\": \"ed399fd0-eda6-4227-99a8-9155251bec15\"}\n",
            "2021-03-24 00:28:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:45927 \"POST /session/3b66764fbba8f980b1c3d62e516524c6/element/ed399fd0-eda6-4227-99a8-9155251bec15/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:28:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:45927/session/3b66764fbba8f980b1c3d62e516524c6/element/018830e3-3682-44b4-969f-40ee4a45f2c1/click {\"id\": \"018830e3-3682-44b4-969f-40ee4a45f2c1\"}\n",
            "2021-03-24 00:28:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:45927 \"POST /session/3b66764fbba8f980b1c3d62e516524c6/element/018830e3-3682-44b4-969f-40ee4a45f2c1/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:28:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "Unhandled error in Deferred:\n",
            "2021-03-24 00:28:46 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:28:46 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:28:46 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:28:46 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 192, in crawl\n",
            "    return self._crawl(crawler, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 196, in _crawl\n",
            "    d = crawler.crawl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1656, in unwindGenerator\n",
            "    return _cancellableInlineCallbacks(gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1571, in _cancellableInlineCallbacks\n",
            "    _inlineCallbacks(None, g, status)\n",
            "--- <exception caught here> ---\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "builtins.TypeError: 'NoneType' object is not iterable\n",
            "\n",
            "2021-03-24 00:28:46 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:28:46 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:28:46 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:28:46 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:28:46 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 00:28:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 00:28:46 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-24 00:28:46 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 00:28:46 [scrapy.extensions.telnet] INFO: Telnet Password: 9fb3bc1065d2031e\n",
            "2021-03-24 00:28:46 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-24 00:28:46 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 00:28:46 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 00:28:46 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping GOOGL - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=GOOGL\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:28:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:35413/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 00:28:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:35413\n",
            "2021-03-24 00:28:47 [urllib3.connectionpool] DEBUG: http://127.0.0.1:35413 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 00:28:47 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:35413/session/2e53d66118550afc09a1064f01d77ddb/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=GOOGL\"}\n",
            "2021-03-24 00:28:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:35413 \"POST /session/2e53d66118550afc09a1064f01d77ddb/url HTTP/1.1\" 200 14\n",
            "2021-03-24 00:28:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:35413/session/2e53d66118550afc09a1064f01d77ddb/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 00:28:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:35413 \"POST /session/2e53d66118550afc09a1064f01d77ddb/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:28:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:35413/session/2e53d66118550afc09a1064f01d77ddb/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 00:28:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:35413 \"POST /session/2e53d66118550afc09a1064f01d77ddb/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:28:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:49 [wiki] INFO: downloading\n",
            "2021-03-24 00:28:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:35413/session/2e53d66118550afc09a1064f01d77ddb/element/c4c8903e-d581-4bf8-b8fe-c7aa9ccca3bc/click {\"id\": \"c4c8903e-d581-4bf8-b8fe-c7aa9ccca3bc\"}\n",
            "2021-03-24 00:28:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:35413 \"POST /session/2e53d66118550afc09a1064f01d77ddb/element/c4c8903e-d581-4bf8-b8fe-c7aa9ccca3bc/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:28:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:28:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:35413/session/2e53d66118550afc09a1064f01d77ddb/element/34b55aff-831b-468f-9867-837c82a87368/click {\"id\": \"34b55aff-831b-468f-9867-837c82a87368\"}\n",
            "2021-03-24 00:28:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:35413 \"POST /session/2e53d66118550afc09a1064f01d77ddb/element/34b55aff-831b-468f-9867-837c82a87368/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:28:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "Unhandled error in Deferred:\n",
            "2021-03-24 00:29:07 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:07 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:07 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:07 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:07 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 192, in crawl\n",
            "    return self._crawl(crawler, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 196, in _crawl\n",
            "    d = crawler.crawl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1656, in unwindGenerator\n",
            "    return _cancellableInlineCallbacks(gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1571, in _cancellableInlineCallbacks\n",
            "    _inlineCallbacks(None, g, status)\n",
            "--- <exception caught here> ---\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "builtins.TypeError: 'NoneType' object is not iterable\n",
            "\n",
            "2021-03-24 00:29:07 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:07 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:07 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:07 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:07 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:07 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 00:29:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 00:29:07 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-24 00:29:07 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 00:29:07 [scrapy.extensions.telnet] INFO: Telnet Password: 1cc5684b31b39652\n",
            "2021-03-24 00:29:07 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-24 00:29:07 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 00:29:07 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 00:29:07 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping GOOG - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=GOOG\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:29:08 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:38879/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 00:29:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:38879\n",
            "2021-03-24 00:29:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:38879 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 00:29:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:38879/session/470bc4a2cea86eb7ed3e52438f03179d/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=GOOG\"}\n",
            "2021-03-24 00:29:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:38879 \"POST /session/470bc4a2cea86eb7ed3e52438f03179d/url HTTP/1.1\" 200 14\n",
            "2021-03-24 00:29:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:38879/session/470bc4a2cea86eb7ed3e52438f03179d/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 00:29:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:38879 \"POST /session/470bc4a2cea86eb7ed3e52438f03179d/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:29:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:38879/session/470bc4a2cea86eb7ed3e52438f03179d/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 00:29:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:38879 \"POST /session/470bc4a2cea86eb7ed3e52438f03179d/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:29:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:11 [wiki] INFO: downloading\n",
            "2021-03-24 00:29:11 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:38879/session/470bc4a2cea86eb7ed3e52438f03179d/element/49e7b0ea-44c1-4cf6-a95c-6c166c157c90/click {\"id\": \"49e7b0ea-44c1-4cf6-a95c-6c166c157c90\"}\n",
            "2021-03-24 00:29:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:38879 \"POST /session/470bc4a2cea86eb7ed3e52438f03179d/element/49e7b0ea-44c1-4cf6-a95c-6c166c157c90/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:29:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:38879/session/470bc4a2cea86eb7ed3e52438f03179d/element/e72c4953-541c-40d3-a2d8-3b65c403b30a/click {\"id\": \"e72c4953-541c-40d3-a2d8-3b65c403b30a\"}\n",
            "2021-03-24 00:29:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:38879 \"POST /session/470bc4a2cea86eb7ed3e52438f03179d/element/e72c4953-541c-40d3-a2d8-3b65c403b30a/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:29:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "Unhandled error in Deferred:\n",
            "2021-03-24 00:29:28 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:28 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:28 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:28 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:28 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:28 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 192, in crawl\n",
            "    return self._crawl(crawler, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 196, in _crawl\n",
            "    d = crawler.crawl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1656, in unwindGenerator\n",
            "    return _cancellableInlineCallbacks(gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1571, in _cancellableInlineCallbacks\n",
            "    _inlineCallbacks(None, g, status)\n",
            "--- <exception caught here> ---\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "builtins.TypeError: 'NoneType' object is not iterable\n",
            "\n",
            "2021-03-24 00:29:28 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:28 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:28 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:28 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:28 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:28 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:28 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 00:29:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 00:29:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-24 00:29:28 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 00:29:28 [scrapy.extensions.telnet] INFO: Telnet Password: 06d3870c80bb5ecf\n",
            "2021-03-24 00:29:28 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-24 00:29:28 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 00:29:28 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 00:29:28 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping TSLA - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=TSLA\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:29:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:48167/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 00:29:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:48167\n",
            "2021-03-24 00:29:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:48167 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 00:29:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:48167/session/2e9b46f6d7a37fb1729b7bae8f066154/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=TSLA\"}\n",
            "2021-03-24 00:29:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:48167 \"POST /session/2e9b46f6d7a37fb1729b7bae8f066154/url HTTP/1.1\" 200 14\n",
            "2021-03-24 00:29:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:48167/session/2e9b46f6d7a37fb1729b7bae8f066154/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 00:29:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:48167 \"POST /session/2e9b46f6d7a37fb1729b7bae8f066154/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:29:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:48167/session/2e9b46f6d7a37fb1729b7bae8f066154/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 00:29:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:48167 \"POST /session/2e9b46f6d7a37fb1729b7bae8f066154/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:29:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:32 [wiki] INFO: downloading\n",
            "2021-03-24 00:29:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:48167/session/2e9b46f6d7a37fb1729b7bae8f066154/element/d805ba31-5669-44af-a1e1-7d2aec7acfc1/click {\"id\": \"d805ba31-5669-44af-a1e1-7d2aec7acfc1\"}\n",
            "2021-03-24 00:29:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:48167 \"POST /session/2e9b46f6d7a37fb1729b7bae8f066154/element/d805ba31-5669-44af-a1e1-7d2aec7acfc1/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:29:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:48167/session/2e9b46f6d7a37fb1729b7bae8f066154/element/bdc5df2f-3cdb-4a7b-9ae5-16ba4a9e4ff8/click {\"id\": \"bdc5df2f-3cdb-4a7b-9ae5-16ba4a9e4ff8\"}\n",
            "2021-03-24 00:29:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:48167 \"POST /session/2e9b46f6d7a37fb1729b7bae8f066154/element/bdc5df2f-3cdb-4a7b-9ae5-16ba4a9e4ff8/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:29:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "Unhandled error in Deferred:\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 192, in crawl\n",
            "    return self._crawl(crawler, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 196, in _crawl\n",
            "    d = crawler.crawl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1656, in unwindGenerator\n",
            "    return _cancellableInlineCallbacks(gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1571, in _cancellableInlineCallbacks\n",
            "    _inlineCallbacks(None, g, status)\n",
            "--- <exception caught here> ---\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "builtins.TypeError: 'NoneType' object is not iterable\n",
            "\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:49 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:49 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 00:29:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 00:29:49 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "Unhandled error in Deferred:\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: Unhandled error in Deferred:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping BRKB - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=BRKB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:29:50 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 192, in crawl\n",
            "    return self._crawl(crawler, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 196, in _crawl\n",
            "    d = crawler.crawl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1656, in unwindGenerator\n",
            "    return _cancellableInlineCallbacks(gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1571, in _cancellableInlineCallbacks\n",
            "    _inlineCallbacks(None, g, status)\n",
            "--- <exception caught here> ---\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "builtins.TypeError: 'NoneType' object is not iterable\n",
            "\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:50 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:29:50 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 00:29:50 [scrapy.extensions.telnet] INFO: Telnet Password: 174dff409411ed05\n",
            "2021-03-24 00:29:50 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-24 00:29:50 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 00:29:50 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 00:29:50 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2021-03-24 00:29:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:34943/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 00:29:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:34943\n",
            "2021-03-24 00:29:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:34943 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 00:29:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:34943/session/a6489404a54187975283cc3cb97c6c09/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=BRKB\"}\n",
            "2021-03-24 00:29:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:34943 \"POST /session/a6489404a54187975283cc3cb97c6c09/url HTTP/1.1\" 200 14\n",
            "2021-03-24 00:29:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:34943/session/a6489404a54187975283cc3cb97c6c09/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 00:29:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:34943 \"POST /session/a6489404a54187975283cc3cb97c6c09/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:29:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:34943/session/a6489404a54187975283cc3cb97c6c09/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 00:29:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:34943 \"POST /session/a6489404a54187975283cc3cb97c6c09/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:29:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:53 [wiki] INFO: downloading\n",
            "2021-03-24 00:29:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:34943/session/a6489404a54187975283cc3cb97c6c09/element/b57c5922-e125-42d3-8f1b-696f5a89b272/click {\"id\": \"b57c5922-e125-42d3-8f1b-696f5a89b272\"}\n",
            "2021-03-24 00:29:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:34943 \"POST /session/a6489404a54187975283cc3cb97c6c09/element/b57c5922-e125-42d3-8f1b-696f5a89b272/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:29:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:29:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:34943/session/a6489404a54187975283cc3cb97c6c09/element/05ede50e-92b7-4bfc-a611-e8bc5507e271/click {\"id\": \"05ede50e-92b7-4bfc-a611-e8bc5507e271\"}\n",
            "2021-03-24 00:29:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:34943 \"POST /session/a6489404a54187975283cc3cb97c6c09/element/05ede50e-92b7-4bfc-a611-e8bc5507e271/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:29:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "Unhandled error in Deferred:\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 192, in crawl\n",
            "    return self._crawl(crawler, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 196, in _crawl\n",
            "    d = crawler.crawl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1656, in unwindGenerator\n",
            "    return _cancellableInlineCallbacks(gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1571, in _cancellableInlineCallbacks\n",
            "    _inlineCallbacks(None, g, status)\n",
            "--- <exception caught here> ---\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "builtins.TypeError: 'NoneType' object is not iterable\n",
            "\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:10 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:10 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 00:30:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 00:30:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-24 00:30:10 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 00:30:10 [scrapy.extensions.telnet] INFO: Telnet Password: 35ed9184d2f4448a\n",
            "2021-03-24 00:30:10 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-24 00:30:10 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 00:30:10 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 00:30:10 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping JPM - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=JPM\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:30:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55265/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 00:30:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:55265\n",
            "2021-03-24 00:30:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55265 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 00:30:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55265/session/c2d7764256f343796755409afbee9f9e/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=JPM\"}\n",
            "2021-03-24 00:30:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55265 \"POST /session/c2d7764256f343796755409afbee9f9e/url HTTP/1.1\" 200 14\n",
            "2021-03-24 00:30:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55265/session/c2d7764256f343796755409afbee9f9e/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 00:30:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55265 \"POST /session/c2d7764256f343796755409afbee9f9e/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:30:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55265/session/c2d7764256f343796755409afbee9f9e/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 00:30:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55265 \"POST /session/c2d7764256f343796755409afbee9f9e/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:30:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:14 [wiki] INFO: downloading\n",
            "2021-03-24 00:30:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55265/session/c2d7764256f343796755409afbee9f9e/element/c769ed57-6cd8-4f23-8068-04cffef91e82/click {\"id\": \"c769ed57-6cd8-4f23-8068-04cffef91e82\"}\n",
            "2021-03-24 00:30:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55265 \"POST /session/c2d7764256f343796755409afbee9f9e/element/c769ed57-6cd8-4f23-8068-04cffef91e82/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:30:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55265/session/c2d7764256f343796755409afbee9f9e/element/bc82b87a-f007-4968-957b-a2785bfa4b7e/click {\"id\": \"bc82b87a-f007-4968-957b-a2785bfa4b7e\"}\n",
            "2021-03-24 00:30:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55265 \"POST /session/c2d7764256f343796755409afbee9f9e/element/bc82b87a-f007-4968-957b-a2785bfa4b7e/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:30:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "Unhandled error in Deferred:\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 192, in crawl\n",
            "    return self._crawl(crawler, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 196, in _crawl\n",
            "    d = crawler.crawl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1656, in unwindGenerator\n",
            "    return _cancellableInlineCallbacks(gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1571, in _cancellableInlineCallbacks\n",
            "    _inlineCallbacks(None, g, status)\n",
            "--- <exception caught here> ---\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "builtins.TypeError: 'NoneType' object is not iterable\n",
            "\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:32 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:32 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 00:30:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 00:30:32 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-24 00:30:32 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 00:30:32 [scrapy.extensions.telnet] INFO: Telnet Password: 042f9bc302ba41b8\n",
            "2021-03-24 00:30:32 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-24 00:30:32 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 00:30:32 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 00:30:32 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping JNJ - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=JNJ\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:30:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:36081/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 00:30:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:36081\n",
            "2021-03-24 00:30:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:36081 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 00:30:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:36081/session/37a34d280ac92f2f2f8ae1eae8c5823f/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=JNJ\"}\n",
            "2021-03-24 00:30:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:36081 \"POST /session/37a34d280ac92f2f2f8ae1eae8c5823f/url HTTP/1.1\" 200 14\n",
            "2021-03-24 00:30:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:34 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:36081/session/37a34d280ac92f2f2f8ae1eae8c5823f/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 00:30:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:36081 \"POST /session/37a34d280ac92f2f2f8ae1eae8c5823f/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:30:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:34 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:36081/session/37a34d280ac92f2f2f8ae1eae8c5823f/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 00:30:34 [urllib3.connectionpool] DEBUG: http://127.0.0.1:36081 \"POST /session/37a34d280ac92f2f2f8ae1eae8c5823f/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:30:34 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:35 [wiki] INFO: downloading\n",
            "2021-03-24 00:30:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:36081/session/37a34d280ac92f2f2f8ae1eae8c5823f/element/0845cb21-d37b-4930-b765-d25f97e5196c/click {\"id\": \"0845cb21-d37b-4930-b765-d25f97e5196c\"}\n",
            "2021-03-24 00:30:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:36081 \"POST /session/37a34d280ac92f2f2f8ae1eae8c5823f/element/0845cb21-d37b-4930-b765-d25f97e5196c/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:30:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:36 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:36081/session/37a34d280ac92f2f2f8ae1eae8c5823f/element/3e86b812-a237-4256-aaf5-2461ee9d0c76/click {\"id\": \"3e86b812-a237-4256-aaf5-2461ee9d0c76\"}\n",
            "2021-03-24 00:30:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:36081 \"POST /session/37a34d280ac92f2f2f8ae1eae8c5823f/element/3e86b812-a237-4256-aaf5-2461ee9d0c76/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:30:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "Unhandled error in Deferred:\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 192, in crawl\n",
            "    return self._crawl(crawler, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 196, in _crawl\n",
            "    d = crawler.crawl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1656, in unwindGenerator\n",
            "    return _cancellableInlineCallbacks(gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1571, in _cancellableInlineCallbacks\n",
            "    _inlineCallbacks(None, g, status)\n",
            "--- <exception caught here> ---\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "builtins.TypeError: 'NoneType' object is not iterable\n",
            "\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:53 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:30:53 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 00:30:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 00:30:53 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-24 00:30:53 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 00:30:53 [scrapy.extensions.telnet] INFO: Telnet Password: 2946c802a20f1d27\n",
            "2021-03-24 00:30:53 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-24 00:30:53 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 00:30:53 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 00:30:53 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping V - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=V\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:30:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:39529/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 00:30:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:39529\n",
            "2021-03-24 00:30:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:39529 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 00:30:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:39529/session/971c8c84a3d60ba86d2d740e2eb2a8b8/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=V\"}\n",
            "2021-03-24 00:30:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:39529 \"POST /session/971c8c84a3d60ba86d2d740e2eb2a8b8/url HTTP/1.1\" 200 14\n",
            "2021-03-24 00:30:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:39529/session/971c8c84a3d60ba86d2d740e2eb2a8b8/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 00:30:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:39529 \"POST /session/971c8c84a3d60ba86d2d740e2eb2a8b8/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:30:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:39529/session/971c8c84a3d60ba86d2d740e2eb2a8b8/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 00:30:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:39529 \"POST /session/971c8c84a3d60ba86d2d740e2eb2a8b8/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:30:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:56 [wiki] INFO: downloading\n",
            "2021-03-24 00:30:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:39529/session/971c8c84a3d60ba86d2d740e2eb2a8b8/element/e151ed5c-2090-4317-aeaf-beb758d1669b/click {\"id\": \"e151ed5c-2090-4317-aeaf-beb758d1669b\"}\n",
            "2021-03-24 00:30:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:39529 \"POST /session/971c8c84a3d60ba86d2d740e2eb2a8b8/element/e151ed5c-2090-4317-aeaf-beb758d1669b/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:30:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:30:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:39529/session/971c8c84a3d60ba86d2d740e2eb2a8b8/element/6613d92f-e6b8-4084-8bd5-52e754b1936b/click {\"id\": \"6613d92f-e6b8-4084-8bd5-52e754b1936b\"}\n",
            "2021-03-24 00:30:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:39529 \"POST /session/971c8c84a3d60ba86d2d740e2eb2a8b8/element/6613d92f-e6b8-4084-8bd5-52e754b1936b/click HTTP/1.1\" 200 14\n",
            "2021-03-24 00:30:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "Unhandled error in Deferred:\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: Unhandled error in Deferred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 192, in crawl\n",
            "    return self._crawl(crawler, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 196, in _crawl\n",
            "    d = crawler.crawl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1656, in unwindGenerator\n",
            "    return _cancellableInlineCallbacks(gen)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1571, in _cancellableInlineCallbacks\n",
            "    _inlineCallbacks(None, g, status)\n",
            "--- <exception caught here> ---\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "builtins.TypeError: 'NoneType' object is not iterable\n",
            "\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:31:14 [twisted] CRITICAL: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/twisted/internet/defer.py\", line 1445, in _inlineCallbacks\n",
            "    result = current_context.run(g.send, result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/crawler.py\", line 88, in crawl\n",
            "    start_requests = iter(self.spider.start_requests())\n",
            "TypeError: 'NoneType' object is not iterable\n",
            "2021-03-24 00:31:14 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 00:31:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 00:31:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-24 00:31:14 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 00:31:14 [scrapy.extensions.telnet] INFO: Telnet Password: 6e5c6355d9926acd\n",
            "2021-03-24 00:31:14 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-24 00:31:14 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 00:31:14 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 00:31:14 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping DIS - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=DIS\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 00:31:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57541/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 00:31:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:57541\n",
            "2021-03-24 00:31:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57541 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 00:31:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:31:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57541/session/a23da30722752e672d8841a97e05bf67/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=DIS\"}\n",
            "2021-03-24 00:31:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57541 \"POST /session/a23da30722752e672d8841a97e05bf67/url HTTP/1.1\" 200 14\n",
            "2021-03-24 00:31:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:31:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57541/session/a23da30722752e672d8841a97e05bf67/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 00:31:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57541 \"POST /session/a23da30722752e672d8841a97e05bf67/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:31:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:31:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57541/session/a23da30722752e672d8841a97e05bf67/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 00:31:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57541 \"POST /session/a23da30722752e672d8841a97e05bf67/element HTTP/1.1\" 200 88\n",
            "2021-03-24 00:31:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 00:31:18 [wiki] INFO: downloading\n",
            "2021-03-24 00:31:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57541/session/a23da30722752e672d8841a97e05bf67/element/f72143ba-75c1-4703-98d7-7564dc0ae840/click {\"id\": \"f72143ba-75c1-4703-98d7-7564dc0ae840\"}\n",
            "2021-03-24 00:31:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57541 \"POST /session/a23da30722752e672d8841a97e05bf67/element/f72143ba-75c1-4703-98d7-7564dc0ae840/click HTTP/1.1\" 400 181\n",
            "2021-03-24 00:31:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c7a5a13afdfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{ticker}_2016_2021.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pageviews-20160101-20210103.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pageviews-20160101-20210103.csv' -> 'DIS_2016_2021.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqT-lk4hqzQu"
      },
      "source": [
        "Scraping DIS - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=DIS\n",
        "2021-03-24 00:31:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57541/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
        "2021-03-24 00:31:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:57541\n",
        "2021-03-24 00:31:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57541 \"POST /session HTTP/1.1\" 200 720\n",
        "2021-03-24 00:31:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
        "2021-03-24 00:31:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57541/session/a23da30722752e672d8841a97e05bf67/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=DIS\"}\n",
        "2021-03-24 00:31:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57541 \"POST /session/a23da30722752e672d8841a97e05bf67/url HTTP/1.1\" 200 14\n",
        "2021-03-24 00:31:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
        "2021-03-24 00:31:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57541/session/a23da30722752e672d8841a97e05bf67/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
        "2021-03-24 00:31:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57541 \"POST /session/a23da30722752e672d8841a97e05bf67/element HTTP/1.1\" 200 88\n",
        "2021-03-24 00:31:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
        "2021-03-24 00:31:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57541/session/a23da30722752e672d8841a97e05bf67/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
        "2021-03-24 00:31:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57541 \"POST /session/a23da30722752e672d8841a97e05bf67/element HTTP/1.1\" 200 88\n",
        "2021-03-24 00:31:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
        "2021-03-24 00:31:18 [wiki] INFO: downloading\n",
        "2021-03-24 00:31:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57541/session/a23da30722752e672d8841a97e05bf67/element/f72143ba-75c1-4703-98d7-7564dc0ae840/click {\"id\": \"f72143ba-75c1-4703-98d7-7564dc0ae840\"}\n",
        "2021-03-24 00:31:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57541 \"POST /session/a23da30722752e672d8841a97e05bf67/element/f72143ba-75c1-4703-98d7-7564dc0ae840/click HTTP/1.1\" 400 181\n",
        "2021-03-24 00:31:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZptyQE4kZZvR"
      },
      "source": [
        "#sp500_tickers = ['AAPL','MSFT','AMZN','FB','SNE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVzC3nqirNfp",
        "outputId": "1937b108-324e-414f-d01a-386b89d39611"
      },
      "source": [
        "wk = wikiTrends(start, end, ticker)\n",
        "link = wk.getURL()\n",
        "print(f'Scraping {ticker} - {link}')\n",
        "process = CrawlerProcess()\n",
        "process.crawl(WikiSpider, url=link)\n",
        "process.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 01:04:15 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-24 01:04:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-24 01:04:15 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-24 01:04:15 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "2021-03-24 01:04:15 [scrapy.extensions.telnet] INFO: Telnet Password: 8cea1fe7d37c075a\n",
            "2021-03-24 01:04:15 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scraping AAPL - https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=AAPL\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 01:04:15 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-24 01:04:15 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-24 01:04:15 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2021-03-24 01:04:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:43563/session {\"capabilities\": {\"firstMatch\": [{}], \"alwaysMatch\": {\"browserName\": \"chrome\", \"platformName\": \"any\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}, \"desiredCapabilities\": {\"browserName\": \"chrome\", \"version\": \"\", \"platform\": \"ANY\", \"goog:chromeOptions\": {\"extensions\": [], \"args\": [\"--headless\", \"--no-sandbox\", \"--disable-dev-shm-usage\"]}}}\n",
            "2021-03-24 01:04:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:43563\n",
            "2021-03-24 01:04:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:43563 \"POST /session HTTP/1.1\" 200 720\n",
            "2021-03-24 01:04:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 01:04:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:43563/session/1b481c690d4a9bb7ee367a8e93f7c9cd/url {\"url\": \"https://pageviews.toolforge.org/?project=en.wikipedia.org&platform=all-access&agent=user&redirects=0&start=2016-01-01&end=2021-01-03&pages=AAPL\"}\n",
            "2021-03-24 01:04:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:43563 \"POST /session/1b481c690d4a9bb7ee367a8e93f7c9cd/url HTTP/1.1\" 200 14\n",
            "2021-03-24 01:04:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 01:04:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:43563/session/1b481c690d4a9bb7ee367a8e93f7c9cd/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div\"}\n",
            "2021-03-24 01:04:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:43563 \"POST /session/1b481c690d4a9bb7ee367a8e93f7c9cd/element HTTP/1.1\" 200 88\n",
            "2021-03-24 01:04:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 01:04:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:43563/session/1b481c690d4a9bb7ee367a8e93f7c9cd/element {\"using\": \"xpath\", \"value\": \"//html/body/main/div[2]/div/div/ul/li[1]/a\"}\n",
            "2021-03-24 01:04:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:43563 \"POST /session/1b481c690d4a9bb7ee367a8e93f7c9cd/element HTTP/1.1\" 200 88\n",
            "2021-03-24 01:04:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 01:04:18 [wiki] INFO: downloading\n",
            "2021-03-24 01:04:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:43563/session/1b481c690d4a9bb7ee367a8e93f7c9cd/element/b641d8de-ab07-4462-9df3-6ae837d05323/click {\"id\": \"b641d8de-ab07-4462-9df3-6ae837d05323\"}\n",
            "2021-03-24 01:04:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:43563 \"POST /session/1b481c690d4a9bb7ee367a8e93f7c9cd/element/b641d8de-ab07-4462-9df3-6ae837d05323/click HTTP/1.1\" 200 14\n",
            "2021-03-24 01:04:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n",
            "2021-03-24 01:04:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:43563/session/1b481c690d4a9bb7ee367a8e93f7c9cd/element/d64e2dc9-4b4a-45a3-91d9-6bc53ae1ae69/click {\"id\": \"d64e2dc9-4b4a-45a3-91d9-6bc53ae1ae69\"}\n",
            "2021-03-24 01:04:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:43563 \"POST /session/1b481c690d4a9bb7ee367a8e93f7c9cd/element/d64e2dc9-4b4a-45a3-91d9-6bc53ae1ae69/click HTTP/1.1\" 200 14\n",
            "2021-03-24 01:04:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}